{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "a5693425-9491-4a0c-98e0-664cf6df248b",
   "metadata": {},
   "source": [
    "<center><img src=\"image.png\" width=500></center>\n",
    "<p>\n",
    "\n",
    "You've recently started a new position as a Data Engineer at an energy company. Previously, analysts on other teams had to manually retrieve and clean data every quarter to understand changes in the sales and capability of different energy types. This process normally took days and was something that most analytsts dreaded. Your job is to automate this process by building a data pipeline. You'll write this data pipeline to pull data each month, helping to provide more rapid insights and free up time for your data consumers.\n",
    "\n",
    "You will achieve this using the `pandas` library and its powerful parsing features. You'll be working with two raw files; `electricity_sales.csv` and `electricity_capability_nested.json`. \n",
    "    \n",
    "Below, you'll find a data dictionary for the `electricity_sales.csv` dataset, which you'll be transforming in just a bit. Good luck!\n",
    "\n",
    "| Field | Data Type |\n",
    "| :---- | :-------: |\n",
    "| period  | `str`        |\n",
    "| stateid | `str` |\n",
    "| stateDescription | `str` |\n",
    "| sectorid | `str` |\n",
    "| sectorName | `str` |\n",
    "| price | `float` |\n",
    "| price-units | `str` |\n",
    "\n",
    "\n",
    "### Instructions\n",
    "\n",
    "1. First, define an extract_tabular_data() function to ingest tabular data. This function will take a single parameter, file_path. If file_path ends with .csv, use the pd.read_csv() function to extract the data. If file_path ends with .parquet, use the pd.read_parquet() function to extract the data. Otherwise, raise an exception and print the message: \"Warning: Invalid file extension. Please try with .csv or .parquet!\".\n",
    "\n",
    "2. Create another function with the name extract_json_data(), which takes a file_path. Use the json_normalize() function from the pandas library to flatten the nested JSON data, and return a pandas DataFrame.\n",
    "\n",
    "3. Next, we'll need to build a function to transform the electricity sales data. To do that, we'll create a function called transform_electricity_sales_data() which takes a single parameter raw_data. raw_data should be of type pd.DataFrame. The transform_electricity_sales_data() needs to fullfil some requirements that are described below in the docstring following the function definition.\n",
    "\n",
    "4. To load a DataFrame to a file, we'll define one more function called load(), which takes a DataFrame and a file_path. If the file_path ends with .csv, load the DataFrame to a CSV file. If instead the file_path ends with .parquet, load the DataFrame to a Parquet file. Otherwise, raise an exception that outputs a message in this format: \"Warning: {filepath} is not a valid file type. Please try again!_\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "408b0fb1-926b-4c41-98e8-15803a1999cb",
   "metadata": {
    "executionCancelledAt": null,
    "executionTime": 10,
    "lastExecutedAt": 1737715360051,
    "lastExecutedByKernel": "50e49d5e-e3f0-4a88-9dc2-1e3514c56d12",
    "lastScheduledRunId": null,
    "lastSuccessfullyExecutedCode": "import pandas as pd\nimport json"
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "e79342a8-2eeb-4bcc-92f0-70c5ebec76e5",
   "metadata": {
    "executionCancelledAt": null,
    "executionTime": 50,
    "lastExecutedAt": 1732713536451,
    "lastExecutedByKernel": "38d619e4-aaba-4b5c-8ea1-6285fbce1f2c",
    "lastScheduledRunId": null,
    "lastSuccessfullyExecutedCode": "import pandas as pd\n\ndef extract_tabular_data(file_path: str):\n    \"\"\"Extract data from a tabular file_format, with pandas.\"\"\"\n    if file_path.endswith(\".csv\"):\n        return pd.read_csv(file_path)\n    \n    elif file_path.endswith(\".parquet\"):\n        return pd.read_parquet(file_path)\n    \n    else:\n        raise Exception(\"Warning: Invalid file extension. Please try with .csv or .parquet!\")\n"
   },
   "outputs": [],
   "source": [
    "def extract_tabular_data(file_path: str):\n",
    "    \"\"\"Extract data from a tabular file_format, with pandas.\"\"\"\n",
    "    try:\n",
    "        if file_path.endswith('.csv'):\n",
    "            data = pd.read_csv(file_path)\n",
    "        elif file_path.endswith(\".parquet\"):\n",
    "            data = pd.read_parquet(file_path)\n",
    "    except Exception as e:\n",
    "        raise Exception(\"Warning: Invalid file extension. Please try with .csv or .parquet!\")\n",
    "    return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "ecbc91c2-e0cc-4ae7-a7e8-ab2a56f1a1a9",
   "metadata": {
    "executionCancelledAt": null,
    "executionTime": 47,
    "lastExecutedAt": 1732713536499,
    "lastExecutedByKernel": "38d619e4-aaba-4b5c-8ea1-6285fbce1f2c",
    "lastScheduledRunId": null,
    "lastSuccessfullyExecutedCode": "import json\n\n# Make sure that extract_json_data() takes a single parameter, file_path\ndef extract_json_data(file_path):\n    \"\"\"Extract and flatten data from a JSON file.\"\"\"\n    # First, read in the JSON file into memory using the json library\n    with open(file_path, \"r\") as json_file:\n        raw_data = json.load(json_file)\n    \n    \n    return pd.json_normalize(raw_data)\n"
   },
   "outputs": [],
   "source": [
    "def extract_json_data(file_path):\n",
    "    \"\"\"Extract and flatten data from a JSON file.\"\"\"\n",
    "\n",
    "    try:\n",
    "        with open(file_path, 'r') as file:\n",
    "            data = json.load(file)\n",
    "            data = pd.json_normalize(data)\n",
    "    except Exception as e:\n",
    "        raise Exception(\"Warning: Invalid file extension. Please try with .json!\")\n",
    "    return data\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "3cc22273-22b8-4f30-8c11-a746f884509f",
   "metadata": {
    "executionCancelledAt": null,
    "executionTime": 51,
    "lastExecutedAt": 1737714942978,
    "lastExecutedByKernel": "50e49d5e-e3f0-4a88-9dc2-1e3514c56d12",
    "lastScheduledRunId": null,
    "lastSuccessfullyExecutedCode": "def transform_electricity_sales_data(raw_data: pd.DataFrame):\n    \"\"\"\n    Transform electricity sales to find the total amount of electricity sold\n    in the residential and transportation sectors.\n    \n    To transform the electricity sales data, you'll need to do the following:\n    - Drop any records with NA values in the `price` column. Do this inplace.\n    - Only keep records with a `sectorName` of \"residential\" or \"transportation\".\n    - Create a `month` column using the first 4 characters of the values in `period`.\n    - Create a `year` column using the last 2 characters of the values in `period`.\n    - Return the transformed `DataFrame`, keeping only the columns `year`, `month`, `stateid`, `price` and `price-units`.\n    \"\"\""
   },
   "outputs": [],
   "source": [
    "def transform_electricity_sales_data(raw_data: pd.DataFrame):\n",
    "    \"\"\"\n",
    "    Transform electricity sales to find the total amount of electricity sold\n",
    "    in the residential and transportation sectors.\n",
    "    \n",
    "    To transform the electricity sales data, you'll need to do the following:\n",
    "    - Drop any records with NA values in the `price` column. Do this inplace.\n",
    "    - Only keep records with a `sectorName` of \"residential\" or \"transportation\".\n",
    "    - Create a `month` column using the first 4 characters of the values in `period`.\n",
    "    - Create a `year` column using the last 2 characters of the values in `period`.\n",
    "    - Return the transformed `DataFrame`, keeping only the columns `year`, `month`, `stateid`, `price` and `price-units`.\n",
    "    \"\"\"\n",
    "\n",
    "    # 1. dropping the NA values from the `price` column\n",
    "    raw_data.dropna(subset=['price'], inplace=True)\n",
    "\n",
    "    # 2. keeping records with residential or transportation sector name\n",
    "    raw_data = raw_data.loc[(raw_data['sectorName'] == \"residential\") | (raw_data['sectorName'] == \"transportation\")]\n",
    "\n",
    "    # 3. creating a new column `year` using the first 4 characters of `period`\n",
    "    raw_data['year'] = raw_data['period'].str[:4]\n",
    "\n",
    "    # 4. creating a new column `month` using the last 2 characters of `period`\n",
    "    raw_data['month'] = raw_data['period'].str[-2:]\n",
    "\n",
    "    # 5. returning the transformed DataFrame with only the required columns\n",
    "    return raw_data[['year', 'month', 'stateid', 'price', 'price-units']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "66e6db3c-ebfa-4f7b-9668-eac8a01f4263",
   "metadata": {
    "executionCancelledAt": null,
    "executionTime": 53,
    "lastExecutedAt": 1732713536600,
    "lastExecutedByKernel": "38d619e4-aaba-4b5c-8ea1-6285fbce1f2c",
    "lastScheduledRunId": null,
    "lastSuccessfullyExecutedCode": "def load(dataframe: pd.DataFrame, file_path: str):\n    # Check to see if the file path ends with .csv or .parquet\n    if file_path.endswith(\".csv\"):\n        dataframe.to_csv(file_path)\n        \n    elif file_path.endswith(\".parquet\"):\n        dataframe.to_parquet(file_path)\n    \n    # Otherwise, throw an exception\n    else: raise Exception(f\"Warning: {file_path} is not a valid file type. Please try again!\")\n"
   },
   "outputs": [],
   "source": [
    "def load(dataframe: pd.DataFrame, file_path: str):\n",
    "    \"\"\"Load a DataFrame to a file in either CSV or Parquet format.\"\"\"\n",
    "\n",
    "    try:\n",
    "        if file_path.endswith('.csv'):\n",
    "            dataframe.to_csv(file_path, index=False)\n",
    "        elif file_path.endswith('.parquet'):\n",
    "            dataframe.to_parquet(file_path, index=False)\n",
    "    except Exception as e:\n",
    "            raise ValueError(f\"Warning: {file_path} is not a valid file type. Please try again!_\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "befd9c30-8fa0-465f-bfc4-675d25d51e62",
   "metadata": {
    "executionCancelledAt": null,
    "executionTime": 113,
    "lastExecutedAt": 1732714584263,
    "lastExecutedByKernel": "38d619e4-aaba-4b5c-8ea1-6285fbce1f2c",
    "lastScheduledRunId": null,
    "lastSuccessfullyExecutedCode": "# Ingest raw electricity capability\nraw_electricity_capability_df = extract_json_data(\"electricity_capability_nested.json\")\nraw_electricity_sales_df = extract_tabular_data(\"electricity_sales.csv\")\n\ncleaned_electricity_sales_df = transform_electricity_sales_data(raw_electricity_sales_df)\n\nload(raw_electricity_capability_df, \"loaded__electricity_capability.parquet\")\nload(cleaned_electricity_sales_df, \"loaded__electricity_sales.csv\")\n"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\STUDSENT\\AppData\\Local\\Temp\\ipykernel_8764\\2906157768.py:21: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  raw_data['year'] = raw_data['period'].str[:4]\n",
      "C:\\Users\\STUDSENT\\AppData\\Local\\Temp\\ipykernel_8764\\2906157768.py:24: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  raw_data['month'] = raw_data['period'].str[-2:]\n"
     ]
    }
   ],
   "source": [
    "# Ready for the moment of truth? It's time to test the functions that you wrote!\n",
    "raw_electricity_capability_df = extract_json_data(\"electricity_capability_nested.json\")\n",
    "raw_electricity_sales_df = extract_tabular_data(\"electricity_sales.csv\")\n",
    "\n",
    "cleaned_electricity_sales_df = transform_electricity_sales_data(raw_electricity_sales_df)\n",
    "\n",
    "load(raw_electricity_capability_df, \"loaded__electricity_capability.parquet\")\n",
    "load(cleaned_electricity_sales_df, \"loaded__electricity_sales.csv\")"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "name": "Welcome to DataCamp Workspaces.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
